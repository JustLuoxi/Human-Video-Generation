# Human Video Generation 
## Paper List
- **Face2Face**: "Real-time Face Capture and Reenactment of RGB Videos" "CVPR" (2016) [[paper](https://web.stanford.edu/~zollhoef/papers/CVPR2016_Face2Face/paper.pdf)][[project](https://web.stanford.edu/~zollhoef/papers/CVPR2016_Face2Face/page.html)]
- **PSGAN**: "Pose Guided Human Video Generation" "ECCV" (2018) [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Ceyuan_Yang_Pose_Guided_Human_ECCV_2018_paper.pdf)]
- **DVP**: "Deep Video Portraits" "Siggraph"(2018) [[paper](https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/paper.pdf)][[project](https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/page.html)]
- **Recycle-GAN**: "Recycle-GAN: Unsupervised Video Retargeting" "ECCV"(2018) [[paper](https://www.cs.cmu.edu/~aayushb/Recycle-GAN/recycle_gan.pdf)][[project](https://www.cs.cmu.edu/~aayushb/Recycle-GAN/)][[code](https://github.com/aayushbansal/Recycle-GAN)]
- **EBDN**: "Everybody Dance Now" "arXiv"(2018) [[paper](https://arxiv.org/pdf/1808.07371.pdf)][[project](https://carolineec.github.io/everybody_dance_now/)]
- **Vid2Vid**: "Video-to-Video Synthesis" "NIPS"(2018) [[paper](https://tcwang0509.github.io/vid2vid/paper_vid2vid.pdf)][[project](https://tcwang0509.github.io/vid2vid/)][[code](https://github.com/NVIDIA/vid2vid)]
- **NAR**: "Neural Animation and Reenactment of Human Actor Videos" "Siggraph"(2019) [[paper](https://arxiv.org/abs/1809.03658)][[project](http://gvv.mpi-inf.mpg.de/projects/wxu/HumanReenactment/)]
- **VPC**: "Deep Video-Based Performance Cloning" "Eurographics"(2019) [[paper](https://arxiv.org/abs/1808.06847)]


## Applications

## Dataset

## Researchers & Teams
